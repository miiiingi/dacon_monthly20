{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "be3c947d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T07:43:22.155974Z",
     "start_time": "2022-04-04T07:43:22.151951Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import random\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "008f5b14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T07:44:19.800420Z",
     "start_time": "2022-04-04T07:43:22.367272Z"
    }
   },
   "outputs": [],
   "source": [
    "# # file_path = 'sim_test_4'\n",
    "# # file_lists = os.listdir(file_path)\n",
    "# datasets, targets,file_name  = [], [], []\n",
    "\n",
    "# img_lists = sorted(glob('data/train/*.png'))\n",
    "# for img in img_lists:\n",
    "#     image_array = np.fromfile(img, np.uint8)\n",
    "#     image = cv2.imdecode(image_array,3)\n",
    "#     image = cv2.resize(image,(224,224),interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "#     if image.shape[1] == 224:\n",
    "#         datasets.append(image)\n",
    "#         targets.append(img.split('\\\\')[1])\n",
    "# #             file_name.append(img)\n",
    "            \n",
    "# # train_test_split(datasets, targets, test_size = 0.1, stratified = True, shuffle = True)\n",
    "# datasets, targets = np.array(datasets), np.array(targets)\n",
    "# datasets = datasets/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c21925f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T07:44:46.683720Z",
     "start_time": "2022-04-04T07:44:19.801386Z"
    }
   },
   "outputs": [],
   "source": [
    "# # file_path = 'sim_test_4'\n",
    "# # file_lists = os.listdir(file_path)\n",
    "# datasets, targets,file_name  = [], [], []\n",
    "\n",
    "# img_lists = sorted(glob('data/test/*.png'))\n",
    "# for img in img_lists:\n",
    "#     image_array = np.fromfile(img, np.uint8)\n",
    "#     image = cv2.imdecode(image_array,3)\n",
    "#     image = cv2.resize(image,(224,224),interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "#     if image.shape[1] == 224:\n",
    "#         datasets.append(image)\n",
    "#         targets.append(img.split('\\\\')[1])\n",
    "# #             file_name.append(img)\n",
    "            \n",
    "# # train_test_split(datasets, targets, test_size = 0.1, stratified = True, shuffle = True)\n",
    "# tests, targets = np.array(datasets), np.array(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1275980e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T04:52:09.588454Z",
     "start_time": "2022-04-04T04:52:09.574334Z"
    }
   },
   "outputs": [],
   "source": [
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "891e0955",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T04:53:19.670606Z",
     "start_time": "2022-04-04T04:52:09.589452Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4277/4277 [01:10<00:00, 61.05it/s]\n"
     ]
    }
   ],
   "source": [
    "train_imgs = [img_load(image) for image in tqdm(train_png)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22e149e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T07:33:09.153604Z",
     "start_time": "2022-04-04T07:33:02.155724Z"
    }
   },
   "outputs": [],
   "source": [
    "from models.se_resnet import *\n",
    "\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.applications import ResNet152V2,ResNet101\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "#from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "#from tensorflow.keras.utils.vis_utils import model_to_dot\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
    "from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af3861ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T07:33:09.607242Z",
     "start_time": "2022-04-04T07:33:09.154577Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def imshow(img, bgr=True):\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    if bgr:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "756c1386",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T07:33:09.622202Z",
     "start_time": "2022-04-04T07:33:09.608240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7587674472479851359\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7803502592\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3982558649747210134\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from IPython.display import display\n",
    "import PIL\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "import tensorflow as tf \n",
    " # 버전 확인, '2.1.0' \n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "get_available_gpus()\n",
    "tf.config.list_physical_devices('GPU')\n",
    "# cmd와 jupyter notebook cell에서 모두 True값이 나와야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "abb62745",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T07:33:09.637163Z",
     "start_time": "2022-04-04T07:33:09.623200Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_coatnet(ROWS,COLS):\n",
    "    mm = coatnet.CoAtNet0(pretrained=\"imagenet\")\n",
    "    x = mm.output\n",
    "    print(x)\n",
    "#     x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x =  Dense(256, activation='elu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(88, activation='softmax')(x)\n",
    "    for layer in mm.layers[30:]:\n",
    "        layer.trainable = True\n",
    "    model = Model(inputs=mm.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "def get_coatnet4(ROWS,COLS):\n",
    "    mm = coatnet.CoAtNet4(pretrained=\"imagenet\")\n",
    "    x = mm.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x =  Dense(256, activation='elu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(88, activation='softmax')(x)\n",
    "    for layer in mm.layers[30:]:\n",
    "        layer.trainable = True\n",
    "    model = Model(inputs=mm.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_coatnet7(ROWS,COLS):\n",
    "    mm = coatnet.CoAtNet7(pretrained=\"imagenet\")\n",
    "    x = mm.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x =  Dense(256, activation='elu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(88, activation='softmax')(x)\n",
    "    for layer in mm.layers[30:]:\n",
    "        layer.trainable = True\n",
    "    model = Model(inputs=mm.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_ConvNeXtLarge(ROWS,COLS):\n",
    "    mm = convnext.ConvNeXtLarge(pretrained=\"imagenet\")\n",
    "    x = mm.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x =  Dense(256, activation='elu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(88, activation='softmax')(x)\n",
    "    for layer in mm.layers[10:]:\n",
    "        layer.trainable = True\n",
    "    model = Model(inputs=mm.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "def BotNetSE33T(ROWS,COLS):\n",
    "    mm = botnet.BotNetSE33T(pretrained=\"imagenet\")\n",
    "    x = mm.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x =  Dense(256, activation='elu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(6, activation='softmax')(x)\n",
    "    for layer in mm.layers[30:]:\n",
    "        layer.trainable = True\n",
    "    model = Model(inputs=mm.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "\n",
    "def CMTBig(ROWS,COLS):\n",
    "    mm = cmt.CMTBig(pretrained=\"imagenet\")\n",
    "    x = mm.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x =  Dense(256, activation='elu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(6, activation='softmax')(x)\n",
    "    for layer in mm.layers[30:]:\n",
    "        layer.trainable = True\n",
    "    model = Model(inputs=mm.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "def EfficientNetV1L2(ROWS,COLS):\n",
    "    mm = efficientnet.EfficientNetV1L2(pretrained=\"imagenet\")\n",
    "    x = mm.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x =  Dense(256, activation='elu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(6, activation='softmax')(x)\n",
    "    for layer in mm.layers[30:]:\n",
    "        layer.trainable = True\n",
    "    model = Model(inputs=mm.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "def EfficientNetV1L2(ROWS,COLS):\n",
    "    mm = volo.VOLO_d5(pretrained=\"imagenet\")\n",
    "    x = mm.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x =  Dense(256, activation='elu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(6, activation='softmax')(x)\n",
    "    for layer in mm.layers[30:]:\n",
    "        layer.trainable = True\n",
    "    model = Model(inputs=mm.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "\n",
    "# def InceptionResNetV2(ROWS,COLS):\n",
    "#     mm = InceptionResNetV2(weights=\"imagenet\", include_top = False,input_shape = (224,224,3))\n",
    "#     x = mm.output\n",
    "#     x = Flatten()(x)\n",
    "#     x = Dropout(0.5)(x)\n",
    "#     x =  Dense(256, activation='elu')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Dense(6, activation='softmax')(x)\n",
    "#     for layer in mm.layers[30:]:\n",
    "#         layer.trainable = True\n",
    "#     model = Model(inputs=mm.input, outputs=x)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e408922",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T07:33:10.464503Z",
     "start_time": "2022-04-04T07:33:09.638160Z"
    }
   },
   "outputs": [],
   "source": [
    "from models.se_resnet import *\n",
    "from keras_cv_attention_models import coatnet\n",
    "\n",
    "OPT = tensorflow.keras.optimizers.Adam(learning_rate=5e-6)\n",
    "\n",
    "def create_model_coatnet(model_name = \"coatnet\"):\n",
    "    stf = StratifiedKFold(n_splits=5)\n",
    "    ROWS = 224\n",
    "    COLS = 224\n",
    "    CHANNELS = 3\n",
    "    CLASSES = 6\n",
    "    \n",
    "    accuracy_lists = []\n",
    "    y_get_dummies = pd.get_dummies(targets)\n",
    "    lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=10, verbose=1)\n",
    "    es = EarlyStopping(monitor=\"val_loss\", patience=25, verbose=1, mode=\"min\", restore_best_weights=True)\n",
    "    for fold, (train_idx, test_idx) in enumerate(stf.split(datasets,targets)):\n",
    "    #     model = ResNet50(input_shape = (ROWS, COLS, CHANNELS), classes = CLASSES)\n",
    "        model_path = model_name\n",
    "        makedirs(model_name)\n",
    "        model = get_coatnet(ROWS,COLS)\n",
    "\n",
    "        opt = tensorflow.keras.optimizers.Adam(learning_rate=5e-6)\n",
    "        model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        filename = os.path.join(model_path, f\"folds{fold}.hdf5\")\n",
    "        sv = keras.callbacks.ModelCheckpoint(\n",
    "                    filename, monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                    save_weights_only=True, mode='auto', save_freq='epoch')\n",
    "        X_train, X_valid = datasets[train_idx], datasets[test_idx]\n",
    "        y_train, y_valid = y_get_dummies.iloc[train_idx], y_get_dummies.iloc[test_idx]\n",
    "        history = model.fit(X_train,y_train,\n",
    "                            epochs=200,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            validation_data =(X_valid,y_valid),\n",
    "                            callbacks=[lr, es,sv])\n",
    "        \n",
    "        \n",
    "def create_model_coatnet4(model_name = \"coatnet4\"):\n",
    "    stf = StratifiedKFold(n_splits=5)\n",
    "    ROWS = 224\n",
    "    COLS = 224\n",
    "    CHANNELS = 3\n",
    "    CLASSES = 6\n",
    "    \n",
    "    accuracy_lists = []\n",
    "    y_get_dummies = pd.get_dummies(targets)\n",
    "    lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.7, patience=8, verbose=1)\n",
    "    es = EarlyStopping(monitor=\"val_loss\", patience=25, verbose=1, mode=\"min\", restore_best_weights=True)\n",
    "    for fold, (train_idx, test_idx) in enumerate(stf.split(datasets,targets)):\n",
    "    #     model = ResNet50(input_shape = (ROWS, COLS, CHANNELS), classes = CLASSES)\n",
    "        model_path = model_name\n",
    "        makedirs(model_name)\n",
    "        model = get_coatnet4(ROWS,COLS)\n",
    "\n",
    "        opt = tensorflow.keras.optimizers.Adam(learning_rate=5e-6)\n",
    "        model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        filename = os.path.join(model_path, f\"folds{fold}.hdf5\")\n",
    "        sv = keras.callbacks.ModelCheckpoint(\n",
    "                    filename, monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                    save_weights_only=True, mode='auto', save_freq='epoch')\n",
    "        X_train, X_valid = datasets[train_idx], datasets[test_idx]\n",
    "        y_train, y_valid = y_get_dummies.iloc[train_idx], y_get_dummies.iloc[test_idx]\n",
    "        history = model.fit(X_train,y_train,\n",
    "                            epochs=200,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            validation_data =(X_valid,y_valid),\n",
    "                            callbacks=[lr, es,sv])\n",
    "                \n",
    "def create_model_coatnet7(model_name = \"coatnet7\"):\n",
    "    stf = StratifiedKFold(n_splits=5)\n",
    "    ROWS = 224\n",
    "    COLS = 224\n",
    "    CHANNELS = 3\n",
    "    CLASSES = 6\n",
    "    \n",
    "    accuracy_lists = []\n",
    "    y_get_dummies = pd.get_dummies(targets)\n",
    "    lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.7, patience=8, verbose=1)\n",
    "    es = EarlyStopping(monitor=\"val_loss\", patience=25, verbose=1, mode=\"min\", restore_best_weights=True)\n",
    "    for fold, (train_idx, test_idx) in enumerate(stf.split(datasets,targets)):\n",
    "    #     model = ResNet50(input_shape = (ROWS, COLS, CHANNELS), classes = CLASSES)\n",
    "        model_path = model_name\n",
    "        makedirs(model_name)\n",
    "        model = get_coatnet7(ROWS,COLS)\n",
    "\n",
    "        opt = tensorflow.keras.optimizers.Adam(learning_rate=5e-6)\n",
    "        model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        filename = os.path.join(model_path, f\"folds{fold}.hdf5\")\n",
    "        sv = keras.callbacks.ModelCheckpoint(\n",
    "                    filename, monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                    save_weights_only=True, mode='auto', save_freq='epoch')\n",
    "        X_train, X_valid = datasets[train_idx], datasets[test_idx]\n",
    "        y_train, y_valid = y_get_dummies.iloc[train_idx], y_get_dummies.iloc[test_idx]\n",
    "        history = model.fit(X_train,y_train,\n",
    "                            epochs=200,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            validation_data =(X_valid,y_valid),\n",
    "                            callbacks=[lr, es,sv])\n",
    "        \n",
    "        \n",
    "def create_model_get_ConvNeXtLarge(model_name = \"get_ConvNeXtLarge\"):\n",
    "    stf = StratifiedKFold(n_splits=5)\n",
    "    ROWS = 224\n",
    "    COLS = 224\n",
    "    CHANNELS = 3\n",
    "    CLASSES = 6\n",
    "    \n",
    "    accuracy_lists = []\n",
    "    y_get_dummies = pd.get_dummies(targets)\n",
    "    lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.7, patience=8, verbose=1)\n",
    "    es = EarlyStopping(monitor=\"val_loss\", patience=25, verbose=1, mode=\"min\", restore_best_weights=True)\n",
    "    for fold, (train_idx, test_idx) in enumerate(stf.split(datasets,targets)):\n",
    "    #     model = ResNet50(input_shape = (ROWS, COLS, CHANNELS), classes = CLASSES)\n",
    "        model_path = model_name\n",
    "        makedirs(model_name)\n",
    "        model = get_ConvNeXtLarge(ROWS,COLS)\n",
    "\n",
    "        opt = OPT\n",
    "        model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        filename = os.path.join(model_path, f\"folds{fold}.hdf5\")\n",
    "        sv = keras.callbacks.ModelCheckpoint(\n",
    "                    filename, monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                    save_weights_only=True, mode='auto', save_freq='epoch')\n",
    "        X_train, X_valid = datasets[train_idx], datasets[test_idx]\n",
    "        y_train, y_valid = y_get_dummies.iloc[train_idx], y_get_dummies.iloc[test_idx]\n",
    "        history = model.fit(X_train,y_train,\n",
    "                            epochs=200,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            validation_data =(X_valid,y_valid),\n",
    "                            callbacks=[lr, es,sv])        \n",
    "        \n",
    "def create_model_get_BotNetSE33T(model_name = \"BotNetSE33T\"):\n",
    "    stf = StratifiedKFold(n_splits=5)\n",
    "    ROWS = 256\n",
    "    COLS = 256\n",
    "    CHANNELS = 3\n",
    "    CLASSES = 6\n",
    "    \n",
    "    accuracy_lists = []\n",
    "    y_get_dummies = pd.get_dummies(targets)\n",
    "    lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.7, patience=8, verbose=1)\n",
    "    es = EarlyStopping(monitor=\"val_loss\", patience=25, verbose=1, mode=\"min\", restore_best_weights=True)\n",
    "    for fold, (train_idx, test_idx) in enumerate(stf.split(datasets256,targets256)):\n",
    "    #     model = ResNet50(input_shape = (ROWS, COLS, CHANNELS), classes = CLASSES)\n",
    "        model_path = model_name\n",
    "        makedirs(model_name)\n",
    "        model = BotNetSE33T(ROWS,COLS)\n",
    "\n",
    "        opt = OPT\n",
    "        model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        filename = os.path.join(model_path, f\"folds{fold}.hdf5\")\n",
    "        sv = keras.callbacks.ModelCheckpoint(\n",
    "                    filename, monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                    save_weights_only=True, mode='auto', save_freq='epoch')\n",
    "        X_train, X_valid = datasets256[train_idx], datasets256[test_idx]\n",
    "        y_train, y_valid = y_get_dummies.iloc[train_idx], y_get_dummies.iloc[test_idx]\n",
    "        history = model.fit(X_train,y_train,\n",
    "                            epochs=200,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            validation_data =(X_valid,y_valid),\n",
    "                            callbacks=[lr, es,sv])        \n",
    "\n",
    "        \n",
    "        \n",
    "def create_model_get_CMTBig(model_name = \"CMTBig\"):\n",
    "    stf = StratifiedKFold(n_splits=5)\n",
    "    ROWS = 224\n",
    "    COLS = 224\n",
    "    CHANNELS = 3\n",
    "    CLASSES = 6\n",
    "    \n",
    "    accuracy_lists = []\n",
    "    y_get_dummies = pd.get_dummies(targets)\n",
    "    lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.7, patience=8, verbose=1)\n",
    "    es = EarlyStopping(monitor=\"val_loss\", patience=25, verbose=1, mode=\"min\", restore_best_weights=True)\n",
    "    for fold, (train_idx, test_idx) in enumerate(stf.split(datasets256,targets)):\n",
    "    #     model = ResNet50(input_shape = (ROWS, COLS, CHANNELS), classes = CLASSES)\n",
    "        model_path = model_name\n",
    "        makedirs(model_name)\n",
    "        model = CMTBig(ROWS,COLS)\n",
    "\n",
    "        opt = OPT\n",
    "        model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        filename = os.path.join(model_path, f\"folds{fold}.hdf5\")\n",
    "        sv = keras.callbacks.ModelCheckpoint(\n",
    "                    filename, monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                    save_weights_only=True, mode='auto', save_freq='epoch')\n",
    "        X_train, X_valid = datasets256[train_idx], datasets256[test_idx]\n",
    "        y_train, y_valid = y_get_dummies.iloc[train_idx], y_get_dummies.iloc[test_idx]\n",
    "        history = model.fit(X_train,y_train,\n",
    "                            epochs=200,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            validation_data =(X_valid,y_valid),\n",
    "                            callbacks=[lr, es,sv])        \n",
    "        \n",
    "        \n",
    "def create_model_get_EfficientNetV1L2(model_name = \"EfficientNetV1L2\"):\n",
    "    stf = StratifiedKFold(n_splits=5)\n",
    "    ROWS = 224\n",
    "    COLS = 224\n",
    "    CHANNELS = 3\n",
    "    CLASSES = 6\n",
    "    \n",
    "    accuracy_lists = []\n",
    "    y_get_dummies = pd.get_dummies(targets)\n",
    "    lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.6, patience=8, verbose=1)\n",
    "    es = EarlyStopping(monitor=\"val_loss\", patience=25, verbose=1, mode=\"min\", restore_best_weights=True)\n",
    "    for fold, (train_idx, test_idx) in enumerate(stf.split(datasets,targets)):\n",
    "    #     model = ResNet50(input_shape = (ROWS, COLS, CHANNELS), classes = CLASSES)\n",
    "        model_path = model_name\n",
    "        makedirs(model_name)\n",
    "        model = EfficientNetV1L2(ROWS,COLS)\n",
    "\n",
    "        opt = OPT\n",
    "        model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        filename = os.path.join(model_path, f\"folds{fold}.hdf5\")\n",
    "        sv = keras.callbacks.ModelCheckpoint(\n",
    "                    filename, monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                    save_weights_only=True, mode='auto', save_freq='epoch')\n",
    "        X_train, X_valid = datasets[train_idx], datasets[test_idx]\n",
    "        y_train, y_valid = y_get_dummies.iloc[train_idx], y_get_dummies.iloc[test_idx]\n",
    "        history = model.fit(X_train,y_train,\n",
    "                            epochs=200,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            validation_data =(X_valid,y_valid),\n",
    "                            callbacks=[lr, es,sv])        \n",
    "        \n",
    "        \n",
    "def create_model_get_VOLO_d5(model_name = \"VOLO_d5\"):\n",
    "    stf = StratifiedKFold(n_splits=5)\n",
    "    ROWS = 224\n",
    "    COLS = 224\n",
    "    CHANNELS = 3\n",
    "    CLASSES = 6\n",
    "    \n",
    "    accuracy_lists = []\n",
    "    y_get_dummies = pd.get_dummies(targets)\n",
    "    lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.6, patience=8, verbose=1)\n",
    "    es = EarlyStopping(monitor=\"val_loss\", patience=25, verbose=1, mode=\"min\", restore_best_weights=True)\n",
    "    for fold, (train_idx, test_idx) in enumerate(stf.split(datasets,targets)):\n",
    "    #     model = ResNet50(input_shape = (ROWS, COLS, CHANNELS), classes = CLASSES)\n",
    "        model_path = model_name\n",
    "        makedirs(model_name)\n",
    "        model = VOLO_d5(ROWS,COLS)\n",
    "\n",
    "        opt =OPT\n",
    "        model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        filename = os.path.join(model_path, f\"folds{fold}.hdf5\")\n",
    "        sv = keras.callbacks.ModelCheckpoint(\n",
    "                    filename, monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                    save_weights_only=True, mode='auto', save_freq='epoch')\n",
    "        X_train, X_valid = datasets[train_idx], datasets[test_idx]\n",
    "        y_train, y_valid = y_get_dummies.iloc[train_idx], y_get_dummies.iloc[test_idx]\n",
    "        history = model.fit(X_train,y_train,\n",
    "                            epochs=200,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            validation_data =(X_valid,y_valid),\n",
    "                            callbacks=[lr, es,sv])        \n",
    "        \n",
    "        \n",
    "def create_model_get_InceptionResNetV2(model_name = \"InceptionResNetV2\"):\n",
    "    stf = StratifiedKFold(n_splits=5)\n",
    "    ROWS = 224\n",
    "    COLS = 224\n",
    "    CHANNELS = 3\n",
    "    CLASSES = 6\n",
    "    \n",
    "    accuracy_lists = []\n",
    "    y_get_dummies = pd.get_dummies(targets)\n",
    "    lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.6, patience=8, verbose=1)\n",
    "    es = EarlyStopping(monitor=\"val_loss\", patience=25, verbose=1, mode=\"min\", restore_best_weights=True)\n",
    "    for fold, (train_idx, test_idx) in enumerate(stf.split(datasets,targets)):\n",
    "    #     model = ResNet50(input_shape = (ROWS, COLS, CHANNELS), classes = CLASSES)\n",
    "        model_path = model_name\n",
    "        makedirs(model_name)\n",
    "        model = InceptionResNetV2(ROWS,COLS)\n",
    "\n",
    "        opt = OPT\n",
    "        model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        filename = os.path.join(model_path, f\"folds{fold}.hdf5\")\n",
    "        sv = keras.callbacks.ModelCheckpoint(\n",
    "                    filename, monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                    save_weights_only=True, mode='auto', save_freq='epoch')\n",
    "        X_train, X_valid = datasets[train_idx], datasets[test_idx]\n",
    "        y_train, y_valid = y_get_dummies.iloc[train_idx], y_get_dummies.iloc[test_idx]\n",
    "        history = model.fit(X_train,y_train,\n",
    "                            epochs=200,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            validation_data =(X_valid,y_valid),\n",
    "                            callbacks=[lr, es,sv])        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5d1ef7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T07:33:13.734276Z",
     "start_time": "2022-04-04T07:33:13.730289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2154, 224, 224, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f480d185",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T04:53:26.965072Z",
     "start_time": "2022-04-04T04:53:26.845746Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4277, 224, 224, 3),\n",
       " 0       transistor-good\n",
       " 1          capsule-good\n",
       " 2       transistor-good\n",
       " 3             wood-good\n",
       " 4           bottle-good\n",
       "              ...       \n",
       " 4272    transistor-good\n",
       " 4273    transistor-good\n",
       " 4274          grid-good\n",
       " 4275        zipper-good\n",
       " 4276         screw-good\n",
       " Name: label, Length: 4277, dtype: object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_imgs).shape, train_y[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe459700",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T07:39:33.943713Z",
     "start_time": "2022-04-04T07:39:33.929749Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "targets = encoder.fit_transform(train_y['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ec185bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T04:53:28.101709Z",
     "start_time": "2022-04-04T04:53:26.980563Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets = np.array(train_imgs)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e611d29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T04:53:28.116635Z",
     "start_time": "2022-04-04T04:53:28.102294Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4277, 224, 224, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b19ff98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T04:53:28.131796Z",
     "start_time": "2022-04-04T04:53:28.117634Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c50b69c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T04:56:48.226153Z",
     "start_time": "2022-04-04T04:53:28.132795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Load pretrained from: C:\\Users\\user\\.keras\\models\\coatnet0_224_imagenet.h5\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1000), dtype=tf.float32, name=None), name='predictions/Softmax:0', description=\"created by layer 'predictions'\")\n",
      "Epoch 1/200\n",
      "321/321 [==============================] - ETA: 0s - loss: 3.4826 - f1_m: 0.0816\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.00000, saving model to CoatNet1111\\folds1.hdf5\n",
      "321/321 [==============================] - 66s 175ms/step - loss: 3.4826 - f1_m: 0.0816 - val_loss: 3.7424 - val_f1_m: 0.0000e+00 - lr: 4.0000e-05\n",
      "Epoch 2/200\n",
      "321/321 [==============================] - ETA: 0s - loss: 2.8790 - f1_m: 0.4232\n",
      "Epoch 00002: val_f1_m did not improve from 0.00000\n",
      "321/321 [==============================] - 54s 168ms/step - loss: 2.8790 - f1_m: 0.4232 - val_loss: 2.3909 - val_f1_m: 0.0000e+00 - lr: 4.0000e-05\n",
      "Epoch 3/200\n",
      "321/321 [==============================] - ETA: 0s - loss: 2.6961 - f1_m: 0.4336\n",
      "Epoch 00003: val_f1_m did not improve from 0.00000\n",
      "321/321 [==============================] - 54s 167ms/step - loss: 2.6961 - f1_m: 0.4336 - val_loss: 1.6778 - val_f1_m: 0.0000e+00 - lr: 4.0000e-05\n",
      "Epoch 4/200\n",
      "139/321 [===========>..................] - ETA: 30s - loss: 2.5664 - f1_m: 0.4720"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14940/3569386928.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_get_dummies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_get_dummies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         history = model.fit(X_train,y_train,\n\u001b[0m\u001b[0;32m     38\u001b[0m                             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jay\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jay\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1219\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1221\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1222\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jay\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    434\u001b[0m     \"\"\"\n\u001b[0;32m    435\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jay\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m       raise ValueError(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jay\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jay\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m       \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jay\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jay\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1104\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1105\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jay\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jay\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jay\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jay\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    548\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jay\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \"\"\"\n\u001b[0;32m   1148\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jay\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1113\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1115\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1116\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1117\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# optimizer = tensorflow.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "#이거썼셈\n",
    "from tensorflow_addons.optimizers import AdamW\n",
    "schedule = tf.optimizers.schedules.PiecewiseConstantDecay(\n",
    "        [10000, 15000], [1e-0, 1e-1, 1e-2])\n",
    "step = tf.Variable(0, trainable=False)\n",
    "wd = lambda: 1e-4 * schedule(step)\n",
    "optimizer = AdamW(learning_rate=4e-5, weight_decay=wd)\n",
    "BATCH_SIZE = 12\n",
    "model_name = 'CoatNet1111'\n",
    "stf = StratifiedKFold(n_splits=10,random_state = 777,shuffle=True)\n",
    "ROWS = 224\n",
    "COLS = 224\n",
    "CHANNELS = 3\n",
    "\n",
    "\n",
    "accuracy_lists = []\n",
    "y_get_dummies = pd.get_dummies(targets)\n",
    "lr = ReduceLROnPlateau(monitor=\"val_f1_m\", factor=0.5, patience=8, verbose=1,mode=\"max\")\n",
    "es = EarlyStopping(monitor=\"val_f1_m\", patience=15, verbose=1, mode=\"max\", restore_best_weights=True)\n",
    "for fold, (train_idx, test_idx) in enumerate(stf.split(datasets,targets)):\n",
    "    if fold == 1:\n",
    "        \n",
    "#     model = ResNet50(input_shape = (ROWS, COLS, CHANNELS), classes = CLASSES)\n",
    "        model_path = model_name\n",
    "#         makedirs(model_name)\n",
    "        model = get_coatnet(ROWS,COLS)\n",
    "        opt = optimizer\n",
    "        model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=[f1_m])\n",
    "        filename = os.path.join(model_path, f\"folds{fold}.hdf5\")\n",
    "        sv = keras.callbacks.ModelCheckpoint(\n",
    "                    filename, monitor='val_f1_m', verbose=1, save_best_only=True,\n",
    "                    save_weights_only=True, mode='max', save_freq='epoch')\n",
    "        X_train, X_valid = datasets[train_idx], datasets[test_idx]\n",
    "        y_train, y_valid = y_get_dummies.iloc[train_idx], y_get_dummies.iloc[test_idx]\n",
    "\n",
    "        history = model.fit(X_train,y_train,\n",
    "                            epochs=200,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            validation_data =(X_valid,y_valid),\n",
    "                            callbacks=[lr, es,sv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6846f3b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T07:34:53.498735Z",
     "start_time": "2022-04-04T07:34:52.530536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Load pretrained from: C:\\Users\\user\\.keras\\models\\coatnet0_224_imagenet.h5\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1000), dtype=tf.float32, name=None), name='predictions/Softmax:0', description=\"created by layer 'predictions'\")\n"
     ]
    }
   ],
   "source": [
    "model = get_coatnet(224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "30978140",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T07:37:48.149977Z",
     "start_time": "2022-04-04T07:37:47.946336Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_weights('CoatNet1111/folds1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f02915b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T07:38:21.686337Z",
     "start_time": "2022-04-04T07:38:21.161470Z"
    }
   },
   "outputs": [],
   "source": [
    "testsets = tests/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9131488b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T07:38:43.713719Z",
     "start_time": "2022-04-04T07:38:33.338409Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = model.predict(testsets) \n",
    "results = []\n",
    "for i in range(len(preds)):\n",
    "    results.append(np.argmax(preds[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8f4cc94c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T07:41:34.324263Z",
     "start_time": "2022-04-04T07:41:34.305314Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "submission['label'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2b6b9302",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T07:41:36.174218Z",
     "start_time": "2022-04-04T07:41:36.161254Z"
    }
   },
   "outputs": [],
   "source": [
    "submission['label'] = encoder.inverse_transform(submission['label'])\n",
    "submission.to_csv(\"submission.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
